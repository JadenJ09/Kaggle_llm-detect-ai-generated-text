{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":7016003,"sourceType":"datasetVersion","datasetId":4033907}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip list","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-21T06:20:30.763524Z","iopub.execute_input":"2023-11-21T06:20:30.763816Z","iopub.status.idle":"2023-11-21T06:20:35.174680Z","shell.execute_reply.started":"2023-11-21T06:20:30.763790Z","shell.execute_reply":"2023-11-21T06:20:35.173594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Paths for input data and saving outputs\ninput_path = '/kaggle/input/llm-detect-ai-generated-text'\noutput_path = '/kaggle/working/'\nmodel_path = '/kaggle/input/distilbert-sst-2/my_model'","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:22:18.671813Z","iopub.execute_input":"2023-11-21T06:22:18.672225Z","iopub.status.idle":"2023-11-21T06:22:33.746657Z","shell.execute_reply.started":"2023-11-21T06:22:18.672192Z","shell.execute_reply":"2023-11-21T06:22:33.745631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0. Load Dataset\ntrain_essays_df = pd.read_csv(f'{input_path}/train_essays.csv')\ntrain_prompts_df = pd.read_csv(f'{input_path}/train_prompts.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:22:57.240554Z","iopub.execute_input":"2023-11-21T06:22:57.242119Z","iopub.status.idle":"2023-11-21T06:22:57.333946Z","shell.execute_reply.started":"2023-11-21T06:22:57.242083Z","shell.execute_reply":"2023-11-21T06:22:57.333146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Load the tokenizer and model from the local directory\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:23:23.828265Z","iopub.execute_input":"2023-11-21T06:23:23.829199Z","iopub.status.idle":"2023-11-21T06:23:26.194284Z","shell.execute_reply.started":"2023-11-21T06:23:23.829155Z","shell.execute_reply":"2023-11-21T06:23:26.193260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Tokenize the dataset and prepare the features for training\ntokenized_data = tokenizer(list(train_essays_df['text']), padding=True, truncation=True, return_tensors=\"pt\")\nlabels = train_essays_df['generated'].values\nlabels_tensor = torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:23:35.817590Z","iopub.execute_input":"2023-11-21T06:23:35.817988Z","iopub.status.idle":"2023-11-21T06:23:37.537546Z","shell.execute_reply.started":"2023-11-21T06:23:35.817957Z","shell.execute_reply":"2023-11-21T06:23:37.536462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Split the data into training and validation sets\ntrain_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_labels, val_labels = train_test_split(\n    tokenized_data['input_ids'], \n    tokenized_data['attention_mask'], \n    labels_tensor, \n    test_size=0.1, \n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:23:42.314814Z","iopub.execute_input":"2023-11-21T06:23:42.315166Z","iopub.status.idle":"2023-11-21T06:23:42.335244Z","shell.execute_reply.started":"2023-11-21T06:23:42.315141Z","shell.execute_reply":"2023-11-21T06:23:42.334309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Fine-tune the model with the prepared dataset\nclass EssaysDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:24:27.934922Z","iopub.execute_input":"2023-11-21T06:24:27.935465Z","iopub.status.idle":"2023-11-21T06:24:27.942039Z","shell.execute_reply.started":"2023-11-21T06:24:27.935416Z","shell.execute_reply":"2023-11-21T06:24:27.940975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the dataset objects\ntrain_encodings = {'input_ids': train_input_ids, 'attention_mask': train_attention_mask}\nval_encodings = {'input_ids': val_input_ids, 'attention_mask': val_attention_mask}\ntrain_dataset = EssaysDataset(train_encodings, train_labels)\nval_dataset = EssaysDataset(val_encodings, val_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:25:22.319513Z","iopub.execute_input":"2023-11-21T06:25:22.319896Z","iopub.status.idle":"2023-11-21T06:25:22.325211Z","shell.execute_reply.started":"2023-11-21T06:25:22.319866Z","shell.execute_reply":"2023-11-21T06:25:22.324276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers import Trainer, TrainingArguments\n\n# Disable wandb\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Set up your training arguments without Weights & Biases reporting\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    report_to=\"none\",  # Disable wandb reporting\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:32:11.653719Z","iopub.execute_input":"2023-11-21T06:32:11.654572Z","iopub.status.idle":"2023-11-21T06:32:11.660640Z","shell.execute_reply.started":"2023-11-21T06:32:11.654536Z","shell.execute_reply":"2023-11-21T06:32:11.659459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:32:13.500374Z","iopub.execute_input":"2023-11-21T06:32:13.500748Z","iopub.status.idle":"2023-11-21T06:32:13.511359Z","shell.execute_reply.started":"2023-11-21T06:32:13.500718Z","shell.execute_reply":"2023-11-21T06:32:13.510415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wandb disabled\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:32:23.776108Z","iopub.execute_input":"2023-11-21T06:32:23.776894Z","iopub.status.idle":"2023-11-21T06:34:07.069640Z","shell.execute_reply.started":"2023-11-21T06:32:23.776860Z","shell.execute_reply":"2023-11-21T06:34:07.068793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Evaluate the model's performance\neval_results = trainer.evaluate()\nprint(eval_results)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:34:30.571994Z","iopub.execute_input":"2023-11-21T06:34:30.572706Z","iopub.status.idle":"2023-11-21T06:34:31.783975Z","shell.execute_reply.started":"2023-11-21T06:34:30.572669Z","shell.execute_reply":"2023-11-21T06:34:31.782802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Save the model for later use or deployment\nmodel.save_pretrained(f'{output_path}/my_model')\ntokenizer.save_pretrained(f'{output_path}/my_model')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:34:43.436833Z","iopub.execute_input":"2023-11-21T06:34:43.437262Z","iopub.status.idle":"2023-11-21T06:34:44.080073Z","shell.execute_reply.started":"2023-11-21T06:34:43.437231Z","shell.execute_reply":"2023-11-21T06:34:44.079089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Use the model to predict test data (unchanged)\nfrom torch.utils.data import Dataset, DataLoader\n\n# Assuming the same tokenizer and model from earlier are still in scope and have been trained\n\n# Load the test data\ntest_essays_path = '/kaggle/input/llm-detect-ai-generated-text/test_essays.csv' \ntest_essays_df = pd.read_csv(test_essays_path)\n\n# Tokenize the test data\ntest_encodings = tokenizer(list(test_essays_df['text']), padding=True, truncation=True, return_tensors=\"pt\")\n\n# Create a test dataset\nclass TestDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: val[idx] for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\ntest_dataset = TestDataset(test_encodings)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:34:54.262934Z","iopub.execute_input":"2023-11-21T06:34:54.263378Z","iopub.status.idle":"2023-11-21T06:34:54.279627Z","shell.execute_reply.started":"2023-11-21T06:34:54.263329Z","shell.execute_reply":"2023-11-21T06:34:54.278559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataLoader for the test dataset\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:35:06.730359Z","iopub.execute_input":"2023-11-21T06:35:06.730970Z","iopub.status.idle":"2023-11-21T06:35:06.735447Z","shell.execute_reply.started":"2023-11-21T06:35:06.730940Z","shell.execute_reply":"2023-11-21T06:35:06.734498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict\nmodel.eval()  # Set the model to evaluation mode\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(model.device)\n        attention_mask = batch['attention_mask'].to(model.device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n        predictions.extend(probabilities[:,1].tolist())  # Get the probability of the \"generated\" class\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:35:16.455176Z","iopub.execute_input":"2023-11-21T06:35:16.456046Z","iopub.status.idle":"2023-11-21T06:35:16.472726Z","shell.execute_reply.started":"2023-11-21T06:35:16.456015Z","shell.execute_reply":"2023-11-21T06:35:16.471928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Format the predictions into the required submission format\nsubmission_df = pd.DataFrame({\n    'id': test_essays_df['id'],\n    'generated': predictions\n})","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:35:24.611075Z","iopub.execute_input":"2023-11-21T06:35:24.611487Z","iopub.status.idle":"2023-11-21T06:35:24.616787Z","shell.execute_reply.started":"2023-11-21T06:35:24.611450Z","shell.execute_reply":"2023-11-21T06:35:24.615948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:35:38.734661Z","iopub.execute_input":"2023-11-21T06:35:38.735493Z","iopub.status.idle":"2023-11-21T06:35:38.752225Z","shell.execute_reply.started":"2023-11-21T06:35:38.735433Z","shell.execute_reply":"2023-11-21T06:35:38.750234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the predictions to a CSV file\nsubmission_path = 'submission.csv'  # Update with the actual path\nsubmission_df.to_csv(submission_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T06:35:49.133857Z","iopub.execute_input":"2023-11-21T06:35:49.134814Z","iopub.status.idle":"2023-11-21T06:35:49.142833Z","shell.execute_reply.started":"2023-11-21T06:35:49.134778Z","shell.execute_reply":"2023-11-21T06:35:49.141690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}